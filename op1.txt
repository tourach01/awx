#!/usr/bin/env bash
set -euo pipefail

# Dépendances
command -v jq >/dev/null 2>&1 || { echo "Erreur: jq est requis." >&2; exit 2; }

# --- Defaults ---
OS_URL="https://localhost:9200"
OS_INDEX="docs"
AUTH=""                  # "user:password" si Basic Auth
APIKEY="${OS_APIKEY:-}"  # ou export OS_APIKEY="xxxxx"
INSECURE=1               # 1 => curl -k par défaut
PRETTY=0                 # 1 => ?pretty
CREATE_INDEX=0           # 0 par défaut (pas de création d'index)
REFRESH="wait_for"       # pour insertion/update par _id
MODE="index"             # index | update | updateq | search
DEBUG=0                  # --debug pour afficher la commande curl et la réponse

# Insertion / Update par _id
DOC_ID=""                # --id pour index/update par _id
UPSERT=0                 # --upsert (pour update par _id)

# Update/Search par requête
QSTRING=""
MAX_DOCS=""
CONFLICTS="abort"        # proceed|abort
UBQ_REFRESH="true"       # refresh=true|false pour _update_by_query

# Search options
SIZE=10
FROM=0
SORT=""                  # "field:asc" ou "field:desc"
SRC_INCLUDES=""
SRC_EXCLUDES=""

# Champs (set) et suppressions (unset)
FIELDS_SPECS=()
UNSETS=()

usage() {
  cat <<'EOF'
Usage (insertion d'un document):
  os_doc.sh [-e URL] [-i INDEX] [-a user:pass] [--secure|--cacert CA.pem] [-P] [--debug] \
            [--create] [-r refresh] [--id ID] [-F k=v]... [--fields "k=v,k2:=JSON"]

Usage (update par _id):
  os_doc.sh --update --id ID [-e URL] [-i INDEX] [-a user:pass] [--secure|--cacert CA.pem] [-P] [--debug] \
            [-F k=v]... [--fields "k=v,k2:=JSON"] [-U champ]... [--unset "c1,c2"] [--upsert] [-r refresh]

Usage (update par requête):
  os_doc.sh --update-by-query -q "env:prod AND code:500" [-e URL] [-i INDEX] [-a user:pass] \
            [--secure|--cacert CA.pem] [-P] [--debug] \
            [-F k=v]... [--fields "k=v,k2:=JSON"] [-U champ]... [--unset "c1,c2"] \
            [--max-docs N] [--conflicts proceed|abort] [--ubq-refresh true|false]

Usage (recherche simple):
  os_doc.sh --search -q "env:prod AND code:200" [-e URL] [-i INDEX] [-a user:pass] \
            [--secure|--cacert CA.pem] [-P] [--debug] \
            [--size N] [--from N] [--sort field:asc] \
            [--source-includes f1,f2] [--source-excludes g1,g2]

Options communes:
  -e URL                 OpenSearch URL (def: https://localhost:9200)
  -i INDEX               Nom d'index (def: docs)
  -a AUTH                Basic auth "user:pass" (ou OS_APIKEY via env)
  --secure               Vérifier TLS (retire -k)
  --cacert FILE          CA à utiliser pour TLS
  -P                     pretty=true
  --debug                Affiche la commande curl (secrets masqués) + en-têtes et corps de réponse

Insertion:
  -F k=v                 Champ string (répétable)        ex: -F env=prod
  -F k:=JSON             Valeur JSON brute               ex: -F code:=200 -F ok:=true -F obj:='{"a":1}'
  --fields LIST          Liste "k=v,k2:=JSON, k3=v3"
  --create               Autoriser la création de l'index si absent (défaut: OFF)
  -r REFRESH             refresh=false|true|wait_for (def: wait_for)
  --id ID                Force l'_id (PUT /_doc/ID), sinon POST (id auto)

Update par _id:
  --update               Mode update par _id (requis avec --id)
  --id ID                Document à mettre à jour
  --upsert               Crée le document s'il n'existe pas (upsert)
  -F/--fields            Champs à set/remplacer
  -U champ               Supprimer un champ (répétable)
  --unset "c1,c2"        Supprimer plusieurs champs

Update par requête:
  --update-by-query      Mode _update_by_query
  -q / --query QS        Requête Lucene (query_string)
  -F/--fields            Champs à set/remplacer
  -U / --unset           Champs à supprimer
  --max-docs N           Limite le nombre de docs affectés
  --conflicts ...        proceed|abort (def: abort)
  --ubq-refresh ...      true|false (def: true)

Recherche:
  --search               Mode recherche (query_string)
  -q / --query QS        Requête Lucene
  --size N               Nombre de hits (def: 10)
  --from N               Offset (def: 0)
  --sort field:asc|desc  Tri
  --source-includes ...  Champs à inclure (ex: "f1,f2")
  --source-excludes ...  Champs à exclure (ex: "g1,g2")
EOF
}

# --- Parse args ---
FIELDS_LIST=""
UNSET_LIST=""
CACERT=""
while [[ $# -gt 0 ]]; do
  case "$1" in
    --update) MODE="update"; shift ;;
    --update-by-query) MODE="updateq"; shift ;;
    --search) MODE="search"; shift ;;
    -e) OS_URL="$2"; shift 2 ;;
    -i) OS_INDEX="$2"; shift 2 ;;
    -a) AUTH="$2"; shift 2 ;;
    --secure) INSECURE=0; shift ;;
    --cacert) CACERT="$2"; shift 2 ;;
    -P) PRETTY=1; shift ;;
    --debug) DEBUG=1; shift ;;
    -r) REFRESH="$2"; shift 2 ;;
    --create) CREATE_INDEX=1; shift ;;
    --id) DOC_ID="$2"; shift 2 ;;
    --upsert) UPSERT=1; shift ;;
    -F) FIELDS_SPECS+=("$2"); shift 2 ;;
    --fields) FIELDS_LIST="$2"; shift 2 ;;
    -U) UNSETS+=("$2"); shift 2 ;;
    --unset) UNSET_LIST="$2"; shift 2 ;;
    -q|--query) QSTRING="$2"; shift 2 ;;
    --max-docs) MAX_DOCS="$2"; shift 2 ;;
    --conflicts) CONFLICTS="$2"; shift 2 ;;
    --ubq-refresh) UBQ_REFRESH="$2"; shift 2 ;;
    --size) SIZE="$2"; shift 2 ;;
    --from) FROM="$2"; shift 2 ;;
    --sort) SORT="$2"; shift 2 ;;
    --source-includes) SRC_INCLUDES="$2"; shift 2 ;;
    --source-excludes) SRC_EXCLUDES="$2"; shift 2 ;;
    -h|--help) usage; exit 0 ;;
    *) echo "Arg inconnu: $1"; usage; exit 1 ;;
  esac
done

# Explode --fields en items -F
if [[ -n "$FIELDS_LIST" ]]; then
  IFS=',' read -r -a _tmp <<< "$FIELDS_LIST"
  for t in "${_tmp[@]}"; do
    t="${t#"${t%%[![:space:]]*}"}"; t="${t%"${t##*[![:space:]]}"}"
    [[ -z "$t" ]] || FIELDS_SPECS+=("$t")
  done
fi
# Explode --unset "a,b,c"
if [[ -n "$UNSET_LIST" ]]; then
  IFS=',' read -r -a _u <<< "$UNSET_LIST"
  for u in "${_u[@]}"; do
    u="${u#"${u%%[![:space:]]*}"}"; u="${u%"${u##*[![:space:]]}"}"
    [[ -z "$u" ]] || UNSETS+=("$u")
  done
fi

# --- Curl helpers ---
CURL_OPTS=( -sS )
(( INSECURE )) && CURL_OPTS+=( -k )
[[ -n "$CACERT" ]] && CURL_OPTS+=( --cacert "$CACERT" )
HEADERS=( -H "Content-Type: application/json" )

if [[ -n "$APIKEY" ]]; then
  HEADERS+=( -H "Authorization: ApiKey $APIKEY" )
elif [[ -n "$AUTH" ]]; then
  CURL_OPTS+=( -u "$AUTH" )
fi

# Versions "printables" (masquées) pour le debug
mask_auth() { local val="$1"; [[ -z "$val" ]] && { echo ""; return; }; local user="${val%%:*}"; echo "${user}:******"; }
mask_apikey() { local v="$1"; local n=${#v}; (( n > 8 )) && echo "${v:0:4}****${v:n-4:4}" || echo "****"; }

CURL_OPTS_PRINT=( "${CURL_OPTS[@]}" )
for ((i=0; i<${#CURL_OPTS_PRINT[@]}; i++)); do
  if [[ "${CURL_OPTS_PRINT[$i]}" == "-u" && $((i+1)) -lt ${#CURL_OPTS_PRINT[@]} ]]; then
    CURL_OPTS_PRINT[$((i+1))]="$(mask_auth "$AUTH")"
  fi
done
HEADERS_PRINT=()
for h in "${HEADERS[@]}"; do
  if [[ "$h" == -H*Authorization:*ApiKey* ]]; then
    HEADERS_PRINT+=( -H "Authorization: ApiKey $(mask_apikey "$APIKEY")" )
  else
    HEADERS_PRINT+=( "$h" )
  fi
done
(( DEBUG )) && CURL_OPTS+=( -i )

http_code() { curl "${CURL_OPTS[@]}" -o /dev/null -w '%{http_code}' "$@"; }
http_json() {
  local args=( "$@" )
  if (( DEBUG )); then
    echo ">>> curl ${CURL_OPTS_PRINT[*]} ${HEADERS_PRINT[*]} ${args[*]}" >&2
  fi
  curl "${CURL_OPTS[@]}" "${HEADERS[@]}" "${args[@]}"
}

# --- Helpers build JSON ---
ensure_index_for_indexing() {
  local code
  code=$(http_code -X HEAD "$OS_URL/$OS_INDEX")
  if [[ "$code" == "404" ]]; then
    if (( CREATE_INDEX )); then
      echo "Création de l'index '$OS_INDEX' (1 shard, 0 replica)…" >&2
      http_json -X PUT "$OS_URL/$OS_INDEX" --data-binary @- <<'JSON' >/dev/null
{"settings":{"number_of_shards":1,"number_of_replicas":0}}
JSON
    else
      echo "Index '$OS_INDEX' absent (création désactivée). Utilise --create si besoin." >&2
      exit 1
    fi
  fi
}

build_set_object_json() {
  local jq_filter='{}'
  local -a jq_args=()
  local idx=0
  for spec in "${FIELDS_SPECS[@]:-}"; do
    if [[ "$spec" =~ ^([^:=]+):=(.*)$ ]]; then
      local k="${BASH_REMATCH[1]}" v="${BASH_REMATCH[2]}"
      jq_args+=( --arg "k$idx" "$k" --argjson "v$idx" "$v" )
      jq_filter+=" | .[\$k$idx] = \$v$idx"
    elif [[ "$spec" =~ ^([^=]+)=(.*)$ ]]; then
      local k="${BASH_REMATCH[1]}" v="${BASH_REMATCH[2]}"
      jq_args+=( --arg "k$idx" "$k" --arg "v$idx" "$v" )
      jq_filter+=" | .[\$k$idx] = \$v$idx"
    else
      echo "Format de champ invalide: '$spec' (attendu k=v ou k:=JSON)" >&2
      exit 1
    fi
    ((idx++))
  done
  jq -n "${jq_args[@]}" "$jq_filter"
}

build_unset_array_json() {
  if [[ ${#UNSETS[@]} -eq 0 ]]; then
    echo "null"
  else
    jq -n --args "${UNSETS[@]}" '$ARGS.positional'
  fi
}

build_update_script_single_body() {
  local set_json unset_json
  set_json="$(build_set_object_json)"
  unset_json="$(build_unset_array_json)"
  if [[ "$set_json" == "{}" && "$unset_json" == "null" ]]; then
    echo "Erreur: aucun champ à set (-F/--fields) ni à unset (-U/--unset)." >&2
    exit 1
  fi
  local script_src='
    if (params.set != null) {
      for (entry in params.set.entrySet()) {
        ctx._source[entry.getKey()] = entry.getValue();
      }
    }
    if (params.unset != null) {
      for (f in params.unset) { ctx._source.remove(f); }
    }
  '
  jq -n \
    --arg src "$script_src" \
    --argjson set "$set_json" \
    --argjson unset "$unset_json" \
    --argjson upsert_do $([[ $UPSERT -eq 1 ]] && echo true || echo false) \
    --argjson upsert_doc "$set_json" '
    ( { script: { lang:"painless", source:$src,
                  params: { set: ( ($set|length==0)? null : $set ), unset: $unset } } } )
    + ( $upsert_do ? { upsert: ( ($upsert_doc|length==0) ? {} : $upsert_doc ) } : {} )'
}

build_update_by_query_body() {
  local set_json unset_json
  set_json="$(build_set_object_json)"
  unset_json="$(build_unset_array_json)"
  if [[ "$set_json" == "{}" && "$unset_json" == "null" ]]; then
    echo "Erreur: aucun champ à set (-F/--fields) ni à unset (-U/--unset)." >&2
    exit 1
  fi
  local script_src='
    if (params.set != null) {
      for (entry in params.set.entrySet()) {
        ctx._source[entry.getKey()] = entry.getValue();
      }
    }
    if (params.unset != null) {
      for (f in params.unset) { ctx._source.remove(f); }
    }
  '
  jq -n \
    --arg q "$QSTRING" \
    --arg src "$script_src" \
    --argjson set "$set_json" \
    --argjson unset "$unset_json" '
    {
      query: { query_string: { query: $q, default_operator: "AND" } },
      script: { lang: "painless", source: $src, params: { set: ( ($set|length==0) ? null : $set ), unset: $unset } }
    }'
}

build_search_body() {
  local field order
  field="${SORT%%:*}"; order="${SORT##*:}"
  [[ "$field" == "$order" ]] && field=""  # pas de ':'
  if [[ -n "$field" ]]; then
    jq -n \
      --arg q "$QSTRING" \
      --argjson from "$FROM" \
      --argjson size "$SIZE" \
      --arg field "$field" \
      --arg order "${order:-asc}" '
      {
        query: { query_string: { query: $q, default_operator: "AND" } },
        from: $from, size: $size,
        sort: [ { ($field): { order: ( ($order=="desc")? "desc":"asc" ) } } ]
      }'
  else
    jq -n \
      --arg q "$QSTRING" \
      --argjson from "$FROM" \
      --argjson size "$SIZE" '
      { query: { query_string: { query: $q, default_operator: "AND" } },
        from: $from, size: $size }'
  fi
}

# --- Main ---
QS=""
(( PRETTY )) && QS="${QS:+$QS&}pretty=true"

case "$MODE" in
  index)
    ensure_index_for_indexing
    QS="${QS:+$QS&}refresh=${REFRESH}"
    SET_JSON="$(build_set_object_json)"
    (( DEBUG )) && { echo ">>> BODY (index):" >&2; echo "$SET_JSON" | jq . >&2 || echo "$SET_JSON" >&2; }
    if [[ -z "$DOC_ID" ]]; then
      http_json -X POST "$OS_URL/$OS_INDEX/_doc?${QS}" --data-binary "$SET_JSON"
    else
      http_json -X PUT "$OS_URL/$OS_INDEX/_doc/$DOC_ID?${QS}" --data-binary "$SET_JSON"
    fi
    echo
    ;;
  update)
    [[ -z "$DOC_ID" ]] && { echo "Erreur: --update nécessite --id <ID>." >&2; exit 1; }
    BODY="$(build_update_script_single_body)"
    (( DEBUG )) && { echo ">>> BODY (update _id=$DOC_ID):" >&2; echo "$BODY" | jq . >&2 || echo "$BODY" >&2; }
    http_json -X POST "$OS_URL/$OS_INDEX/_update/$DOC_ID?${QS}${QS:+&}refresh=${REFRESH}" --data-binary "$BODY"
    echo
    ;;
  updateq)
    [[ -z "$QSTRING" ]] && { echo "Erreur: --update-by-query nécessite -q/--query." >&2; exit 1; }
    BODY="$(build_update_by_query_body)"
    UQS="conflicts=$( [[ "$CONFLICTS" == "proceed" ]] && echo proceed || echo abort )"
    UQS+="&refresh=$( [[ "$UBQ_REFRESH" == "true" ]] && echo true || echo false )"
    [[ -n "$MAX_DOCS" ]] && UQS+="&max_docs=$MAX_DOCS"
    (( PRETTY )) && UQS+="&pretty=true"
    (( DEBUG )) && { echo ">>> BODY (update_by_query):" >&2; echo "$BODY" | jq . >&2 || echo "$BODY" >&2; }
    http_json -X POST "$OS_URL/$OS_INDEX/_update_by_query?${UQS}" --data-binary "$BODY"
    echo
    ;;
  search)
    [[ -z "$QSTRING" ]] && { echo "Erreur: --search nécessite -q/--query." >&2; exit 1; }
    BODY="$(build_search_body)"
    # _source filters via querystring
    [[ -n "$SRC_INCLUDES" ]] && QS="${QS:+$QS&}_source_includes=$SRC_INCLUDES"
    [[ -n "$SRC_EXCLUDES" ]] && QS="${QS:+$QS&}_source_excludes=$SRC_EXCLUDES"
    (( DEBUG )) && { echo ">>> BODY (search):" >&2; echo "$BODY" | jq . >&2 || echo "$BODY" >&2; }
    http_json -X POST "$OS_URL/$OS_INDEX/_search?${QS}" --data-binary "$BODY"
    echo
    ;;
  *)
    usage; exit 1 ;;
esac
